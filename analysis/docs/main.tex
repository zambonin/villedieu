\documentclass[12pt]{article}

\usepackage[T1]{fontenc}
\usepackage[a4paper, margin=1.5cm]{geometry}
\usepackage[colorlinks, urlcolor=blue, citecolor=red]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amsfonts, booktabs, enumitem, parskip}

\begin{document}

\textsc{Graduate Program in Computer Science,
  Universidade Federal de Santa Catarina} \\
\textsc{INE410104 (Design and Analysis of Algorithms)}

\textsc{Solutions to the 1\textsuperscript{st} Set of Exercises} \\
\textsc{Gustavo Zambonin, Matheus S. P. Bittencourt}

\begin{enumerate}
    \item 
    \begin{enumerate}
        \item Let the functions that represent the time complexities of algorithms $A$ and $B$ be $f(n) = n^{3}$ and $g(n) = 128n^{2}$, respectively, with $n \in \mathbb{N}$. Further, consider $t(n) = \frac{f(n)}{g(n)} \Rightarrow \frac{n}{128}$. By the ratio $t(n)$, algorithm $A$ is faster than $B$ when $n > 128$.
        \item Let the old and new computers be named $N_{1}$ and $N_{2}$, respectively, and $f(n) = 2^{n}$. The equation $t = \frac{2^{N_{1}}}{s}$ gives the time spent to solve an instance of $f(n)$ such that $N_{1}$ executes $s$ instructions per second. Analogously, let $t = \frac{2^{N_{2}}}{20s}$ represent the previous equation for the new computer. Solving for $N_{2}$ in terms of $N_{1}$:
        \begin{align*}
            \frac{2^{N_{1}}}{s} = \frac{2^{N_{2}}}{20s} \\
            2^{N_{2}} = 20 \cdot 2^{N_{1}} \\
            N_{2} = N_{1} + \log_{2} 20 \\
            N_{2} \approx N_{1} + 4.32.
        \end{align*}
        Ergo, one cannot execute $f(2n)$ and expect comparable results on $N_{2}$, since $N_{2} \ll 2 N_{1}$.
    \end{enumerate}
    \item
    \begin{enumerate}
        \item
        \begin{table}[htbp]
            \renewcommand{\arraystretch}{1.2}
            \setlength{\tabcolsep}{7pt}
            \centering
            \caption{Largest $n \in \mathbb{N}$ such that $t = \frac{f(n)}{10^{10}}$.}
            \begin{tabular}{l*{7}{r}}
                \toprule
                    & 1 second & 1 minute & 1 hour & 1 day & 1 month & 1 year & 1 century \\
                    $\log_{2} n$ & & & & & & \\
                    $\sqrt{n}$   &  \\
                    $n$          &  \\
                    $n \log_{2} n$ & \\
                    $n^{2}$ & \\
                    $n^{3}$ & \\
                    $2^{n}$ & \\
                    $n!$ & \\
                \bottomrule
            \end{tabular}
            \label{tab:1}
        \end{table}
        \item The ``find-min'' operation is fastest on the binary and Fibonacci heaps, since it is constant. The ``delete-min'' operation should be fastest on the Fibonacci heap, since an $\mathcal{O}(\log n)$ time complexity represents an amortised asymptotic upper bound, whereas the other heaps' $\Theta(\log n)$ is tight. Indeed, given a worst case scenario, both operations take exactly the same time to complete, but otherwise the Fibonacci heap does not take $\log n$ steps to finish the operation in average. The ``insert'' operation is fastest on the binomial and Fibonacci heaps. Thus, the Fibonacci heap is overall the fastest data structure when compared to binary and binomial heaps.
    \end{enumerate}
\end{enumerate}

\end{document}
